{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcde790b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57497eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_data_paths, celeb2mask, CustomDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get data paths\n",
    "data_paths = get_data_paths(celeb_img_path=\"../data/dataset_celebs/imgs_256/*.jpg\",\n",
    "                            celeb_mask_path=\"../data/dataset_celebs/masks_256/\")\n",
    "data_paths = [i for i in data_paths if i[0] == \"community_dataset\"]\n",
    "# data_paths = [i for i in data_paths if i[0] != \"community_dataset\"]\n",
    "# np.random.shuffle(data_paths)\n",
    "# data_paths = data_paths[:100]\n",
    "\n",
    "# split data\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, random_state=42)\n",
    "test_paths, val_paths = train_test_split(test_paths, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_paths)}, Val: {len(val_paths)}, Test: {len(test_paths)}\")\n",
    "\n",
    "# Datasets\n",
    "train_dataset = CustomDataset(train_paths)\n",
    "val_dataset = CustomDataset(val_paths)\n",
    "test_dataset = CustomDataset(test_paths)\n",
    "\n",
    "# Dataloaders\n",
    "torch.manual_seed(42)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "del data_paths, train_paths, test_paths, val_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b2c58",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretrained_models import PretrainedModel, train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "epochs = 15\n",
    "test_metrics = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd636d",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2c9e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Weights tests\n",
    "arch = \"unet\"\n",
    "loss_name = \"BCEWeighted\"\n",
    "optimizer_name = \"Adam\"\n",
    "encoder_name = \"xception\"\n",
    "weights = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "           [0.5, 3, 3, 1, 0.5, 3, 2, 0.5, 1.5, 1.5, 1.5],\n",
    "           [0.02335332, 2.29093098, 4.60850608, 0.95243978, 0.16392607, 3.69650905, 10.48914825, 0.05858025, 2.10530202, 4.27744651, 1.27002274]]\n",
    "weight_name = [\"equals\", \"weighted_empirical\", \"weighted_proportional\"]\n",
    "\n",
    "for weight_num, weight in enumerate(weights):\n",
    "    params = {\"weight\":weight, \"optimizer_name\":optimizer_name,\n",
    "              \"lr\": 1e-3, \"weight_decay\": 0,\n",
    "              \"loss_name\": loss_name, \"arch\":arch,\n",
    "              \"encoder_name\":encoder_name, \"automatic_optimization\":True}\n",
    "    # callbacks utils\n",
    "    logger_name = f\"baseline_{weight_name[weight_num]}\"\n",
    "    logger_save_path = \"../data/logs/pretrained/\"\n",
    "    callback_name = f\"baseline_{weight_name[weight_num]}\"\n",
    "    callback_save_path = \"../data/models/pretrained/\"\n",
    "    # train loop\n",
    "    test_metrics = train_loop(params, test_metrics, logger_name, logger_save_path, callback_name,\n",
    "                              callback_save_path, epochs, train_dataloader, val_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ade650c",
   "metadata": {},
   "source": [
    "## Backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eba7bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_metrics = pd.DataFrame()\n",
    "arch = \"unet\"\n",
    "loss_name = \"BCEWeighted\"\n",
    "optimizer_name = \"Adam\"\n",
    "backbones = [\"timm-efficientnet-b3\", \"timm-mobilenetv3_large_100\"]\n",
    "weight = [0.02335332, 2.29093098, 4.60850608, 0.95243978, 0.16392607, 3.69650905, 10.48914825, 0.05858025, 2.10530202, 4.27744651, 1.27002274]\n",
    "\n",
    "for encoder_name in backbones:\n",
    "    print(f\"Encoder: {encoder_name}\")\n",
    "    # params\n",
    "    params = {\"weight\":weight, \"optimizer_name\":optimizer_name,\n",
    "              \"lr\": 1e-3, \"weight_decay\": 0,\n",
    "              \"loss_name\": loss_name, \"arch\":arch,\n",
    "              \"encoder_name\":encoder_name, \"automatic_optimization\":True}\n",
    "    # callbacks utils\n",
    "    logger_name = f\"{encoder_name}\"\n",
    "    logger_save_path = \"../data/logs/pretrained/\"\n",
    "    callback_name = f\"{encoder_name}\"\n",
    "    callback_save_path = \"../data/models/pretrained/\"\n",
    "    # train loop\n",
    "    test_metrics = train_loop(params, test_metrics, logger_name, logger_save_path, callback_name,\n",
    "                              callback_save_path, epochs, train_dataloader, val_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e929e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1a9a09",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d3bf2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_metrics = pd.DataFrame()\n",
    "arch = \"unet\"\n",
    "loss_name = \"BCEWeighted\"\n",
    "encoder_name = \"xception\"\n",
    "optimizers = [\"AdamP\", \"AdaBelief\"]\n",
    "weight = [0.02335332, 2.29093098, 4.60850608, 0.95243978, 0.16392607, 3.69650905, 10.48914825, 0.05858025, 2.10530202, 4.27744651, 1.27002274]\n",
    "\n",
    "for optimizer_name in optimizers:   \n",
    "    print(f\"Optimizer: {optimizer_name}\")    \n",
    "    # params\n",
    "    params = {\"weight\":weight, \"optimizer_name\":optimizer_name,\n",
    "              \"lr\": 1e-4, \"weight_decay\": 0,\n",
    "              \"loss_name\": loss_name, \"arch\":arch,\n",
    "              \"encoder_name\":encoder_name, \"automatic_optimization\":False}\n",
    "    # callbacks ut*ils\n",
    "    logger_name = f\"{optimizer_name}\"\n",
    "    logger_save_path = \"../data/logs/pretrained/\"\n",
    "    callback_name = f\"{optimizer_name}\"\n",
    "    callback_save_path = \"../data/models/pretrained/\"\n",
    "    # train loop\n",
    "    test_metrics = train_loop(params, test_metrics, logger_name, logger_save_path, callback_name,\n",
    "                              callback_save_path, epochs, train_dataloader, val_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612a552",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd3f35d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_metrics = pd.DataFrame()\n",
    "arch = \"unet\"\n",
    "encoder_name = \"xception\"\n",
    "optimizer_name = \"Adam\"\n",
    "weight = [0.02335332, 2.29093098, 4.60850608, 0.95243978, 0.16392607, 3.69650905, 10.48914825, 0.05858025, 2.10530202, 4.27744651, 1.27002274]\n",
    "losses = [\"DiceLoss\", \"FocalLoss\", \"TverskyLoss\", \"BiasLoss\"]\n",
    "\n",
    "for loss_name in losses:  \n",
    "    print(f\"Loss: {loss_name}\")\n",
    "    # params\n",
    "    params = {\"weight\":weight, \"optimizer_name\":optimizer_name,\n",
    "              \"lr\": 1e-4, \"weight_decay\": 0,\n",
    "              \"loss_name\": loss_name, \"arch\":arch,\n",
    "              \"encoder_name\":encoder_name, \"automatic_optimization\":True}\n",
    "    # callbacks utils\n",
    "    logger_name = f\"{loss_name}\"\n",
    "    logger_save_path = \"../data/logs/pretrained/\"\n",
    "    callback_name = f\"{loss_name}\"\n",
    "    callback_save_path = \"../data/models/pretrained/\"\n",
    "    # train loop\n",
    "    test_metrics = train_loop(params, test_metrics, logger_name, logger_save_path, callback_name,\n",
    "                              callback_save_path, epochs, train_dataloader, val_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d996f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e1f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc65d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe149ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
