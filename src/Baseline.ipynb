{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf4c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde790b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57497eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "from xml.dom import minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse xml file\n",
    "input_files = []\n",
    "labels = []\n",
    "\n",
    "xmldoc = minidom.parse('data/training.xml')\n",
    "inputs_features = xmldoc.getElementsByTagName('srcimg')\n",
    "labels_features = xmldoc.getElementsByTagName('labelimg')\n",
    "\n",
    "for idx, _ in enumerate(inputs_features):\n",
    "    # get paths\n",
    "    input_path = inputs_features[idx].attributes[\"name\"].value\n",
    "    label_path = labels_features[idx].attributes[\"name\"].value\n",
    "    # check names\n",
    "    assert os.path.basename(input_path.replace(\"\\\\\", \"/\")), os.path.basename(label_path.replace(\"\\\\\", \"/\"))\n",
    "    # update storages\n",
    "    input_files.append(os.path.join(\"data\", input_path.replace(\"\\\\\", \"/\")))\n",
    "    labels.append(os.path.join(\"data\", label_path.replace(\"\\\\\", \"/\")))\n",
    "\n",
    "# zip data\n",
    "data_paths = list(zip(input_files, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = [i for i in data_paths if \"female03\" not in i[0]]\n",
    "test_paths = [i for i in data_paths if \"female03\" in i[0]]\n",
    "\n",
    "print(len(train_paths), len(test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbba605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show images\n",
    "for _ in range(5):\n",
    "    idx = np.random.choice(range(len(input_files)))\n",
    "    img = cv2.imread(input_files[idx])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    label = cv2.imread(labels[idx])\n",
    "    label = cv2.cvtColor(label, cv2.COLOR_BGR2RGB)\n",
    "                           \n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,10))\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(\"Img\")\n",
    "    ax[1].imshow(label)\n",
    "    ax[1].set_title(\"Labels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloder(tf.keras.utils.Sequence):\n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_paths: dict, batch_size=1, shuffle=False):\n",
    "        self.data_paths = data_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(data_paths))\n",
    "        # classes\n",
    "        self.class2idx = {cl:idx for idx, cl in enumerate(CLASSES.keys(), start=1)}\n",
    "        self.idx2class = {idx:cl for cl, idx in self.class2idx.items()}\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(data_paths)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # collect batch data\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data_img = cv2.imread(self.data_paths[j][0])\n",
    "            data_img = cv2.cvtColor(cv2.resize(data_img, (256, 256)), cv2.COLOR_BGR2RGB)\n",
    "            data_img = (data_img.astype(np.float32) / 255).astype(np.float32)\n",
    "            label_temp = cv2.imread(self.data_paths[j][1])\n",
    "            label_temp = cv2.cvtColor(cv2.resize(label_temp, (256, 256)), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # update classes\n",
    "#             label_img = np.expand_dims((np.sum(label_img, axis=-1) > 0).astype(np.float32), axis=-1)\n",
    "            label_img = []\n",
    "\n",
    "            for cl, vals in CLASSES.items():\n",
    "                temp = np.zeros_like(label_temp)\n",
    "                temp[(label_temp[..., 0]==vals[0]) & (label_temp[..., 1]==vals[1]) & (label_temp[..., 2]==vals[2])] = 1\n",
    "                label_img.append(temp[..., 0])\n",
    "\n",
    "            mask = np.stack(label_img, axis=-1).astype(np.float32)\n",
    "\n",
    "            data.append([data_img, mask])\n",
    "            \n",
    "        \n",
    "        # transpose list of lists\n",
    "        \n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return len(self.indexes) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a729db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "CLASSES = {\"background\": [0,0,0],\n",
    "           \"lips\": [255, 0, 0], \"eye\": [0,255,0], \"nose\": [0,0,255],\"hair\": [255, 255, 0],\n",
    "            \"brows\":[255, 0, 255], \"teeth\": [255,255,255], \"face\": [128, 128, 128],\n",
    "            \"ears\":[0,255,255], \"glasses\":[0,128,128], \"beard\":[255, 192, 192]}\n",
    "\n",
    "train_paths, val_paths = train_test_split(data_paths, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ae108",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = Dataloder(train_paths, batch_size=16, shuffle=True)\n",
    "valid_dataloader = Dataloder(val_paths, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b2c58",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('./best_model.h5', save_weights_only=True, save_best_only=True, mode='min'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=3, ),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=0, restore_best_weights=True)\n",
    "]\n",
    "  \n",
    "sm.set_framework('tf.keras')\n",
    "model = sm.Unet(backbone_name='efficientnetb3', classes=len(CLASSES), activation=\"softmax\")\n",
    "\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=[0.5,2,1,1,1,1,1,1,1,1,1])\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "model.compile(tf.keras.optimizers.Adam(0.001), loss=total_loss, \n",
    "              metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a999bd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# fit model\n",
    "history = model.fit(train_dataloader,\n",
    "                    steps_per_epoch=len(train_dataloader),\n",
    "                    epochs=30,\n",
    "                    validation_data=valid_dataloader,\n",
    "                    validation_steps=len(valid_dataloader),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA\n",
    "for x, y in valid_dataloader:\n",
    "    break\n",
    "pred = model.predict(x)[5]\n",
    "\n",
    "plt.imshow(x[5])\n",
    "plt.show()\n",
    "\n",
    "for i in range(11):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(y[5][..., i])\n",
    "    ax[1].imshow(pred[..., i])\n",
    "    plt.title(list(CLASSES.keys())[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed8e48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ME\n",
    "img = cv2.imread(\"me2.jpg\")\n",
    "img = cv2.resize(img, (256, 256))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = (img.astype(np.float32) / 255).astype(np.float32)\n",
    "\n",
    "pred = model.predict(img)[0]\n",
    "\n",
    "plt.imshow(img[0])\n",
    "plt.show()\n",
    "\n",
    "for i in range(11):\n",
    "    plt.imshow(pred[..., i])\n",
    "    plt.title(list(CLASSES.keys())[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3769089",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"me2.jpg\")\n",
    "img = cv2.resize(img, (256, 256))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = (img.astype(np.float32) / 255).astype(np.float32)\n",
    "\n",
    "pred = model.predict(img)[0]\n",
    "res = np.zeros_like(img[0])\n",
    "\n",
    "for i in range(11):\n",
    "    res[np.where(pred[..., i] > 0.5)] = list(CLASSES.values())[i]\n",
    "    \n",
    "res = res.astype(int)\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9fcd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac6d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cdbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d28f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
